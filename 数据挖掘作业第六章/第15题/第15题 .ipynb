{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据挖掘第六章作业 第15题"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a) 挖掘合著者关系 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 频繁模式挖掘也适用于寻找论文的合著者关系。\n",
    "1. 可以把一篇论文的合著者看成是一条事务，在事务中，每个合著者是一个项。\n",
    "1. 用Apriori算法或其他频繁项集挖掘的实现，挖掘合著者关系的频繁项集。\n",
    "1. 处在频繁项集中的合著者，可以认为是经常进行合作的合著者关系。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以复用7题的代码\n",
    "先在小型的合著者关系数据集上测试一下代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Jiawei Han', 'Yan Shi'}, {'Xiaofeng Meng', 'Jian Pei', 'Yan Shi'}, {'Laks V. S. Lakshmanan', 'Xiaokui Xiao', 'Jian Pei'}, {'Yufei Tao', 'Xiaokui Xiao', 'Wang-Chien Lee'}, {'Zhenhui Li', 'Wang-Chien Lee', 'Jiawei Han'}, {'Jiawei Han', 'Hong Cheng', 'Xifeng Yan'}, {'Jiawei Han', 'Xifeng Yan', 'Philip S. Yu'}, {'Jiawei Han', 'Hong Cheng', 'Dong Xin'}, {'Hong Cheng', 'Xifeng Yan', 'Dong Xin'}, {'Hong Cheng', 'Xifeng Yan', 'Philip S. Yu'}, {'Yuqing Wu', 'Kun-Lung Wu', 'Philip S. Yu'}, {'Yuqing Wu', 'Kun-Lung Wu', 'Philip S. Yu'}, {'Yuqing Wu', 'Kun-Lung Wu', 'Philip S. Yu'}, {'Yuqing Wu', 'Kun-Lung Wu', 'Philip S. Yu'}, {'Yuqing Wu', 'Kun-Lung Wu', 'Philip S. Yu'}, {'Yuqing Wu', 'Kun-Lung Wu', 'Philip S. Yu'}, {'Yuqing Wu', 'Kun-Lung Wu', 'Philip S. Yu'}, {'Yuqing Wu', 'Kun-Lung Wu', 'Philip S. Yu'}, {'Yuqing Wu', 'Kun-Lung Wu', 'Philip S. Yu'}]\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "import pandas as pd\n",
    "def load_data(path):\n",
    "        data = pd.read_csv(path)\n",
    "        num = data.iloc[:, -2]\n",
    "        y = data.iloc[:, -1]\n",
    "\n",
    "        return num, y\n",
    "\n",
    "# 生成事务合集，每篇文章作为一个集合\n",
    "def getShoppingCart(orders, items):\n",
    "    numOfOrder = len(set(orders))\n",
    "    shoppingCart = [set() for _ in range(numOfOrder)]\n",
    "    for j in range(len(orders)):\n",
    "        shoppingCart[orders[j]-1].add(items[j])\n",
    "    return shoppingCart\n",
    "\n",
    "orders, items = load_data('mini.csv')\n",
    "shoppingCart = getShoppingCart(orders, items)\n",
    "print(shoppingCart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQUENT = 5\n",
    "\n",
    "\n",
    "class Apriori:\n",
    "\n",
    "    # 判断itemList是否在order中\n",
    "    def __contains(self, order, itemList):\n",
    "        for item in itemList:\n",
    "            if item not in order:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # 计算itemList在shoppingCart中出现的次数\n",
    "    def count(self, itemList, shoppingCart):\n",
    "        count = 0\n",
    "        for order in shoppingCart:\n",
    "            if (self.__contains(order, itemList)):\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    # 生成下一层的itemList\n",
    "    def __generate_next_itemList(self, itemList):\n",
    "        next_itemList = []\n",
    "        for i in range(len(itemList)):\n",
    "            for j in range(i+1, len(itemList)):\n",
    "                if itemList[i][:-1] == itemList[j][:-1]:\n",
    "                    newList = [x for x in itemList[i]]\n",
    "                    newList.append(itemList[j][-1])\n",
    "                    next_itemList.append(newList)\n",
    "        return next_itemList\n",
    "\n",
    "    # 生成第一层的itemList\n",
    "    def __getFirstItemLists(self, items):\n",
    "        firstItemList = [[x] for x in set(items)]\n",
    "        return firstItemList\n",
    "\n",
    "    # 过滤掉不满足最小支持度的itemList\n",
    "    def __filter(self, itemLists, shoppingCart):\n",
    "        filterList = []\n",
    "        for itemList in itemLists:\n",
    "            if self.count(itemList, shoppingCart) >= FREQUENT:\n",
    "                filterList.append(itemList)\n",
    "        return filterList\n",
    "\n",
    "    # 主函数,也是对外接口\n",
    "    def analyze(self, items, shoppingCart):\n",
    "        itemLists = self.__getFirstItemLists(items)\n",
    "        totalFrequentItemLists = []\n",
    "\n",
    "        while len(itemLists) > 0:\n",
    "            filteredItemLists = []\n",
    "            filteredItemLists = self.__filter(itemLists, shoppingCart)\n",
    "            if (len(filteredItemLists) > 0):\n",
    "                totalFrequentItemLists.append(filteredItemLists)\n",
    "            nextItemList = self.__generate_next_itemList(filteredItemLists)\n",
    "            itemLists = nextItemList\n",
    "\n",
    "        return totalFrequentItemLists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Jiawei Han'], ['Kun-Lung Wu'], ['Philip S. Yu'], ['Yuqing Wu']], [['Kun-Lung Wu', 'Philip S. Yu'], ['Kun-Lung Wu', 'Yuqing Wu'], ['Philip S. Yu', 'Yuqing Wu']], [['Kun-Lung Wu', 'Philip S. Yu', 'Yuqing Wu']]]\n"
     ]
    }
   ],
   "source": [
    "# 输出所有的频繁项集\n",
    "ap = Apriori()\n",
    "print(ap.analyze(items, shoppingCart))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b) 频繁模式挖掘的评估度量"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章讨论的评估度量包括：\n",
    "- 提升度\n",
    "- 卡方值\n",
    "- 全置信度\n",
    "- 最大置信度\n",
    "- Kulc值\n",
    "- 余弦度量"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在论文数据集这样的大型数据集中，作者的出现往往是非常稀疏的。因此，存在着大量的零事务，所有度量的零不变性是很重要的。\n",
    "\n",
    "具有零不变性的度量有：全置信度, 最大置信度, Kulc值, 余弦度量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kun-Lung Wu', 'Philip S. Yu']\n",
      "max_confidence: 1.0\n",
      "all_confidence: 0.8181818181818182\n",
      "Kulc: 0.9090909090909092\n",
      "cosine: 0.9045340337332909\n",
      "----------------\n",
      "['Kun-Lung Wu', 'Yuqing Wu']\n",
      "max_confidence: 1.0\n",
      "all_confidence: 1.0\n",
      "Kulc: 1.0\n",
      "cosine: 1.0\n",
      "----------------\n",
      "['Philip S. Yu', 'Yuqing Wu']\n",
      "max_confidence: 1.0\n",
      "all_confidence: 0.8181818181818182\n",
      "Kulc: 0.9090909090909092\n",
      "cosine: 0.9045340337332909\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "def conditionP(a, b):\n",
    "    countb = ap.count([b], shoppingCart)\n",
    "    coountab = ap.count([a, b], shoppingCart)\n",
    "    return coountab/countb\n",
    "\n",
    "\n",
    "\n",
    "ans = ap.analyze(items, shoppingCart)\n",
    "two = ans[1]\n",
    "for pair in two:\n",
    "    a = pair[0]\n",
    "    b = pair[1]\n",
    "    max_confidence = max(conditionP(a, b), conditionP(b, a))\n",
    "    all_confidence = min(conditionP(a, b), conditionP(b, a))\n",
    "    Kulc = 0.5*(conditionP(a, b) + conditionP(b, a))\n",
    "    cosine = (conditionP(a, b) * conditionP(b, a))**0.5\n",
    "    print(pair)\n",
    "    print('max_confidence:', max_confidence)\n",
    "    print('all_confidence:', all_confidence)\n",
    "    print('Kulc:', Kulc)\n",
    "    print('cosine:', cosine)\n",
    "    print('----------------')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kulc 和 余弦度量考虑了合著者双方的条件概率，而且不受零事务的影响，应当是布景会的指标。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c) 导师关系和指导周期"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑学生和导师的关系。\n",
    "\n",
    "当学生发表论文时，一般作者中会包含导师的名字。\n",
    "\n",
    "但是当导师发表论文时，一般作者中不一定包含学生的名字。\n",
    "\n",
    "因此，导师和学生双方的关系是不对称的，他们的条件概率也是不对称的，应该相差较大。\n",
    "\n",
    "所以，我们可以考虑计算频繁模式中的全置信度和最大置信度，通过它们的差，来判断导师和学生的关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kun-Lung Wu', 'Philip S. Yu']\n",
      "difference:  0.18181818181818177\n",
      "----------------\n",
      "['Kun-Lung Wu', 'Yuqing Wu']\n",
      "difference:  0.0\n",
      "----------------\n",
      "['Philip S. Yu', 'Yuqing Wu']\n",
      "difference:  0.18181818181818177\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for pair in two:\n",
    "    a = pair[0]\n",
    "    b = pair[1]\n",
    "    max_confidence = max(conditionP(a, b), conditionP(b, a))\n",
    "    all_confidence = min(conditionP(a, b), conditionP(b, a))\n",
    "    print(pair)\n",
    "    print('difference: ', max_confidence - all_confidence)\n",
    "    print('----------------')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在某个频繁模式中，最大置信度和全置信度的差较大时，可以猜测两者有导师学生关系。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于指导的近似周期，可以分时段统计频繁模式，然后计算频繁模式中的全置信度和最大置信度的差，通过差的变化趋势，来判断指导周期。\n",
    "\n",
    "当指导周期结束后，两人的关系会发生变化，或者两人不再合作，或者两人的关系会变得更加对称，这都会使得全置信度和最大置信度的差变小。于是我们可以想定差较大的部分就是两人的指导周期。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
